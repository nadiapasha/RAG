# Question Answering app with Mistral, llama-index and Weaviate
# Gist
This FastAPI app uses llama-index to implement RAG. The vector-datase used is Weaviate, installed locally with Docker.  
# Credits:    
1. https://github.com/AIAnytime/Haystack-and-Mistral-7B-RAG-Implementation  
2. https://github.com/katanaml/llm-ollama-llamaindex-invoice-cpu
